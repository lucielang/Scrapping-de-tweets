{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage des données\n",
    "\n",
    "Après avoir scrappé, il nous faut tenir compte de plusieurs choses pour nettoyer les bases de données et les fusionner :\n",
    "- dans un premier temps, on convertit les dates dans un format date permettant ensuite de trier et de réarranger la table dans le bon ordre temporel.\n",
    "- les cases vides susceptibles d'apparaître dans les colonnes \"Likes\", \"Views\", etc... sont remplacées par des 0 (il n'y a eu en effet aucun like par exemple).\n",
    "- on fusionne les tables et on les trie par date\n",
    "- enfin, on supprime les bots, définis dans notre code par une répétition de 4 tweets faisant moins de 1000 vues (car certains tweets qui se répètent peuvent être des titres d'article)\n",
    "\n",
    "\n",
    "Nettoyage : mettre des 0 et des colonnes par mois et semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Fonction 1 : Nettoyer les données numériques\n",
    "def convertir_en_nombre(valeur):\n",
    "    \"\"\"\n",
    "    Convertit les chaînes de caractères (ex: '1.2K') en nombres.\n",
    "    Remplace NaN par 0.\n",
    "    \"\"\"\n",
    "    if pd.isna(valeur):  # Si la valeur est NaN, retourne 0\n",
    "        return 0\n",
    "    if isinstance(valeur, str):  # Vérifie si la valeur est une chaîne de caractères\n",
    "        valeur = valeur.strip()  # Supprime les espaces inutiles\n",
    "        if 'K' in valeur:  # Si la valeur contient 'K', multiplier par 1 000\n",
    "            return float(valeur.replace('K', '')) * 1000\n",
    "        elif 'M' in valeur:  # Si la valeur contient 'M', multiplier par 1 000 000\n",
    "            return float(valeur.replace('M', '')) * 1000000\n",
    "    try:\n",
    "        return float(valeur)  # Sinon, convertir directement en nombre\n",
    "    except ValueError:\n",
    "        return 0  # Si la conversion échoue, retourner 0\n",
    "\n",
    "# Fonction 2 : Conversion des dates\n",
    "def convert_date(value, previous_date):\n",
    "    \"\"\"\n",
    "    Convertit les valeurs de date relative ou absolue en objets datetime.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        value = str(value).strip()  # S'assurer que la valeur est une chaîne\n",
    "        \n",
    "        # Cas 1 : Format \"Nov 5\" (pas d'année explicite)\n",
    "        elif len(value.split()) == 2:\n",
    "            value_with_year = value + \" 2024\"  # Ajouter l'année par défaut\n",
    "            return datetime.strptime(value_with_year, '%b %d %Y')\n",
    "        \n",
    "        # Cas 2 : Format complet \"Nov 5, 2023\"\n",
    "        elif len(value.split()) == 3:\n",
    "            return datetime.strptime(value, '%b %d, %Y')\n",
    "        \n",
    "        # Cas 3 : Valeur non reconnue\n",
    "        else:\n",
    "            return pd.NaT\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la conversion de la date : {value} -> {e}\")\n",
    "        return pd.NaT  # Retourne NaT si la conversion échoue\n",
    "\n",
    "# Fonction 3 : Nettoyer et transformer un fichier\n",
    "def process_file(file_path):\n",
    "    \"\"\"\n",
    "    Nettoie et transforme un fichier Excel, en ajoutant des colonnes converties\n",
    "    et en générant deux fichiers de sortie :\n",
    "    1. Toutes les données transformées.\n",
    "    2. Données filtrées avant une date spécifique.\n",
    "    \"\"\"\n",
    "    print(f\"Traitement du fichier : {file_path}\")\n",
    "    # Charger les données\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Nettoyer les colonnes numériques\n",
    "    colonnes_a_nettoyer = ['Comments', 'Repost', 'Likes', 'Views']\n",
    "    for colonne in colonnes_a_nettoyer:\n",
    "        if colonne in df.columns:\n",
    "            df[colonne] = df[colonne].apply(convertir_en_nombre)\n",
    "    \n",
    "    # Convertir les dates\n",
    "    converted_dates = []\n",
    "    previous_date = None\n",
    "    for value in df['Date']:\n",
    "        if previous_date is None:  # La première ligne doit être une date absolue\n",
    "            converted_date = convert_date(value, datetime(2024, 1, 1))  # Supposition du début\n",
    "        else:\n",
    "            converted_date = convert_date(value, previous_date)\n",
    "        converted_dates.append(converted_date)\n",
    "        if pd.notna(converted_date):  # Mettre à jour la référence seulement si la conversion a réussi\n",
    "            previous_date = converted_date\n",
    "    \n",
    "    # Ajouter les colonnes converties\n",
    "    df['ConvertedDate'] = converted_dates\n",
    "    df['YearWeek'] = df['ConvertedDate'].dt.strftime('%Y-%U')\n",
    "    df['YearMonth'] = df['ConvertedDate'].dt.strftime('%Y-%m')\n",
    "    \n",
    "\n",
    "    # Filtrer les données pour garder uniquement les dates avant le 1er décembre 2024\n",
    "    cutoff_date = datetime(2024, 12, 1)\n",
    "    df_filtered = df[df['ConvertedDate'] < cutoff_date]\n",
    "    \n",
    "    # Sauvegarder les données filtrées\n",
    "    output_file_filtered = file_path.replace('.xlsx', '_nettoye.xlsx')\n",
    "    df_filtered.to_excel(output_file_filtered, index=False)\n",
    "    print(f\"Fichier avec les données filtrées sauvegardé : {output_file_filtered}\")\n",
    "\n",
    "# Liste des fichiers Excel à traiter\n",
    "files = ['/home/onyxia/work/Scrapping_tweets/Scrapping_tweets/tweets_stay_1.xlsx', 'tweets_group_stay.xlsx']\n",
    "\n",
    "# Boucle principale pour traiter chaque fichier\n",
    "for file in files:\n",
    "    process_file(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tri après fusion des tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les deux fichiers filtrés\n",
    "file_1 = 'tweets_group_leave_nettoye.xlsx'\n",
    "file_2 = 'tweets_group_stay_nettoye.xlsx'\n",
    "\n",
    "# Charger les données des deux fichiers\n",
    "df1 = pd.read_excel(file_1)\n",
    "df2 = pd.read_excel(file_2)\n",
    "\n",
    "# Fusionner les deux tables\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Vérifier que la colonne 'ConvertedDate' est bien en format datetime\n",
    "if not pd.api.types.is_datetime64_any_dtype(merged_df['ConvertedDate']):\n",
    "    merged_df['ConvertedDate'] = pd.to_datetime(merged_df['ConvertedDate'])\n",
    "\n",
    "# Trier par date décroissante\n",
    "merged_df = merged_df.sort_values(by='ConvertedDate', ascending=False)\n",
    "\n",
    "# Sauvegarder la table fusionnée et triée\n",
    "output_file = 'tweets_fusionnes.xlsx'\n",
    "merged_df.to_excel(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer les bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('tweets_fusionnes')\n",
    "\n",
    "# Vérifier que les colonnes nécessaires existent\n",
    "if 'Content' not in df.columns or 'Views' not in df.columns:\n",
    "    raise ValueError(\"Les colonnes 'Content' et 'Views' sont nécessaires pour ce traitement.\")\n",
    "\n",
    "# Compter les occurrences de chaque tweet\n",
    "content_counts = df['Content'].value_counts()\n",
    "\n",
    "# Filtrer les contenus apparaissant au moins 4 fois\n",
    "repeated_contents = content_counts[content_counts >= 4].index\n",
    "\n",
    "# Identifier les tweets répétitifs\n",
    "repeated_tweets = df[df['Content'].isin(repeated_contents)]\n",
    "\n",
    "# Identifier les groupes où un tweet a plus de 1000 vues\n",
    "to_keep = repeated_tweets.groupby('Content')['Views'].max()  # Max des vues pour chaque groupe\n",
    "valid_tweets = to_keep[to_keep > 1000].index  # Conserver les groupes avec au moins un tweet > 1000 vues\n",
    "\n",
    "# Séparer les tweets répétitifs en deux groupes\n",
    "# Tweets à conserver (au moins 1 tweet > 1000 vues dans le groupe)\n",
    "tweets_to_keep = repeated_tweets[repeated_tweets['Content'].isin(valid_tweets)]\n",
    "\n",
    "# Tweets à supprimer (aucun tweet > 1000 vues dans le groupe)\n",
    "tweets_to_remove = repeated_tweets[~repeated_tweets['Content'].isin(valid_tweets)]\n",
    "\n",
    "# Combiner les données finales\n",
    "#df_cleaned = pd.concat([df[~df['Content'].isin(repeated_contents)], tweets_to_keep])\n",
    "\n",
    "# Sauvegarder les tweets répétitifs supprimés\n",
    "# tweets_to_remove.to_excel('removed_repeated_tweets.xlsx', index=False)\n",
    "\n",
    "# Sauvegarder la base nettoyée\n",
    "#df_cleaned.to_excel('cleaned_tweets.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
