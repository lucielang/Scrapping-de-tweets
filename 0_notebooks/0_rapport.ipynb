{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport du projet de programmation\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Le projet de programmation que nous avons entrepris se veut proposer des formes d'analyses et de réponses au sujet des thématiques et problématiques qui touchent l'utilisation des réseaux sociaux à des fins d'information, notamment Twitter. En effet, la construction de véritables empires médiatiques est croissante et tend à se normaliser. Le choix de s'intéresser directement à ce qui se passe sur un des réseaux sociaux les plus utilisés au monde nous a donc semblé pertinent dans la mesure où Twitter est sujet à de multiples controverses. **comment ça se fait que quand tu viens de créer un compte tu tombes sur une page de trump ou de elon musk fin bon pas à moi (en vrai jsuis chaud qu'on en parle)** Dans les événements récents, de nombreuses personnalités ont notamment appelé à quitter Twitter (de grands journaux tels que le *Guardian*, des journalistes ainsi que des personnalités politiques). Mais qu'en est-il des utilisateurs ? Quelle attitude adoptent-ils face à cela ?\n",
    "\n",
    "Les enjeux de ce projet portent ainsi concrètement sur le niveau de prises de position, qu'elles aillent dans un sens favorable ou défavorable à ce que nous disons être une main mise d'Elon Musk sur Twitter. De fait, ce projet interroge aussi une forme d'éveil citoyen et politique des utilisateurs face aux informations qu'ils reçoivent, mais aussi le niveau d'implication et de mobilisation dans ce type de discussions.\n",
    "Ainsi, ce projet suit une ligne directrice orientée, car nous partons effectivement du principe que les utilisateurs se posent la question et réagissent à la mouvance qui consiste à quitter Twitter (nous-même partons du fait que nous identifions un problème de désinformation sur Twitter).\n",
    "\n",
    "**présentation du plan d'action**\n",
    "Concrètement, nous avons décidé de scrapper Twitter pour obtenir une base de données qui remonte jusqu'à.... : nous avons ainsi collecté le nom d'utilisateur, la date, le contenu du tweet, le nombre de likes, de réponses, de retweets et de vues.\n",
    "\n",
    "Pour analyser les tweets, nous avons mis en place du NLP pour tenter d'obtenir une information supplémentaire sur les contenus des tweets, et ne pas seulement s'en tenir à des informations très descriptives reflétées par le nombre de likes, réponses, retweets et vues.\n",
    "\n",
    "on apprend à thibault qui attend "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par installer les différentes bibliothèques qui seront nécessaires à l'exécution des codes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.55.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting datetime\n",
      "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting zope.interface (from datetime)\n",
      "  Downloading zope.interface-7.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.12/site-packages (from datetime) (2024.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from zope.interface->datetime) (75.3.0)\n",
      "Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
      "Downloading zope.interface-7.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "Installing collected packages: zope.interface, datetime\n",
      "Successfully installed datetime-5.5 zope.interface-7.2\n",
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: selenium in /opt/conda/lib/python3.12/site-packages (4.27.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/conda/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/conda/lib/python3.12/site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/conda/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/conda/lib/python3.12/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /opt/conda/lib/python3.12/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /opt/conda/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/conda/lib/python3.12/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/conda/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /opt/conda/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/conda/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/conda/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install datetime\n",
    "!pip install openpyxl\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base de données\n",
    "\n",
    "### 2.1 Scrapping\n",
    "Une fois ceci fait, la première étape va consister à scrapper Twitter. La façon dont nous avons procédé a été la suivante :\n",
    "\n",
    "- Tout d'abord nous avons installé le framework Selenium, afin de naviguer automatiquement sur le site de Twitter et faire défiler les tweets sur la page qui nous intéressait. En effet nous souhaitions récolter les tweets dans leur ordre de publication, c'est-à-dire dans l'onglet \"Récents\" de la page de recherche de Twitter. \n",
    "- Pour cela, nous avons créé un compte Twitter : l'utilisateur et le mot de passe sont remplis lors de l'exécution du code. Dans la barre de recherche nous avons donc entré les mots clés que nous voulions voir ressortir dans les tweets (les mots liés au fait de quitter Twitter et le mot \"Musk\"), de janvier 2024 à décembre 2024. \n",
    "- Afin de récupérer les tweets et les stocker dans un dataframe, nous avons identifié l'auteur, le contenu, la date, le nombre de vues, de likes, de reposts et de commentaires de chaque tweet en trouvant l'emplacement de ces éléments dans la structure HTML de la page web, puis avons placé chacun d'eux dans une liste. Cela nous a permis d'obtenir un tableau mis sous format Excel.\n",
    "\n",
    "**ATTENTION : Le code met du temps à tourner, nous avons donc fourni directement les bases de données dont nous nous servons sous format Excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous exécutons le code plusieurs fois en changeant les mots clefs : **rajouter les mots clefs**:\n",
    "- quit twitter musk\n",
    "- leave or leaving toussa\n",
    "- remain blabla\n",
    "\n",
    "Nous allons garder plusieurs tables :\n",
    "- une table avec les mots clefs \"quit\" et \"leave\" : nous gardons ici de façon générale les personnes qui disent quitter Twitter\n",
    "- une table qui regroupe les personnes qui disent rester sur Twitter (mots clefs \"remain on\", \"still on\")\n",
    "- une table qui regroupe ces deux tables, qui réunit donc les personnes qui *s'expriment* sur le sujet, et qui se posent donc la question de rester ou non sur Twitter.\n",
    "\n",
    "Nous ajoutons à cela une phase de nettoyage de ces tables : \n",
    "- pour regrouper les tables, nous les ajoutons les unes aux autres, convertissons le tout dans un format date qui permet ensuite de trier et de réarranger la table dans le bon ordre temporel.\n",
    "- les cases vides susceptibles d'apparaître dans les colonnes \"Likes\", \"Views\", etc... sont remplacées par des 0 (il n'y a eu en effet aucun like par exemple).\n",
    " **Nettoyer la table ? quelles dates on garde ? mettre des 0 là où y a des trous => mieux si philipa s'en charge?**. Nous avons ainsi en colonnes blablabla. **présenter une sortie du tableau excel ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A FAIRE, LUCIE A LES CODES**\n",
    "+ code pour regrouper quit et not leave\n",
    "\n",
    "+ convertir tout en format date\n",
    "Les dates que nous obtenons directement après avoir scrappé ne sont pas dans un format \"date\" qui simplifie les calculs. Nous utilisons donc le module *datetime* de Python, notamment la fonction *datetime.strptime* pour convertir une chaîne de caractères représentant une date ou une heure en un objet datetime. En effet, nous avons été particulièrement vigilants au fait que notre code devait faire en sorte d'assigner la bonne date aux dates apparaissant sous le format \"6mn\", \"1h\" : dans notre code, nous faisons en sorte de prendre en compte la date suivant la précédente. Ainsi, nous avons pu régler des problèmes de date d'exécution du code.\n",
    "\n",
    "+ trier \n",
    "\n",
    "+ cases vides remplacées par des 0\n",
    "\n",
    "PAS OUBLIER DE METTRE LES ANCIENNES (celles avec le scrapping) ET LES NOUVELLES TABLES (nettoyées et belles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous nous présentons une sortie de notre table **mettre le nom de la table (celle avec tout)** qui affiche les 10 premières lignes (en affichant tout le contenu, ce que permet *display*) de notre table :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Modifier les paramètres pour afficher plus de contenu dans chaque cellule\n",
    "pd.set_option('display.max_colwidth', None)  # Affiche tout le contenu des colonnes\n",
    "pd.set_option('display.max_columns', None)  # Affiche toutes les colonnes\n",
    "pd.set_option('display.width', 1000)  # Ajuste la largeur totale de l'affichage\n",
    "\n",
    "# Charger et afficher le fichier Excel\n",
    "df = pd.read_excel('tweets_fusionnes.xlsx')\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà à quoi ressemble notre sortie : l'étape d'après est le NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 NLP\n",
    "\n",
    "partie de thibault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "Une fois la base de données nettoyée après avoir été obtenue par scrapping, l'objectif est de l'organiser et de créer les variables nécessaires à la création d'indices, eux-mêmes nécessaires à la réalisation de statistiques descriptives et d'analyses.\n",
    "\n",
    "### Rajout d'une colonne YearWeek et YearMonth\n",
    "Nous avons choisi d'analyser nos données en les groupant par semaine et par mois, selon les observations que nous voulons faire, ce qui permet d'avoir une analyse assez fine des tendances sans être trop exposés aux fluctuations journalières.\n",
    "\n",
    "Dans le code suivant, nous avons créé une nouvelle table avec un rajout des colonnes Yearweek et YearMonth. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code 0_rap_convertdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premiers graphiques\n",
    "Une fois ceci fait, nous pouvons sortir nos premiers graphiques :\n",
    "- d'abord le **nombre de tweets par semaine**, ce qui permet de relever certaines tendances\n",
    "- puis sur un autre graphique nous représentons le **nombre de likes, de retweets et de réponses par semaine** en **valeur absolue** puis en **valeur pondérée** par le nombre de tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code 1_rap_nbrtweets\n",
    "code 2_rap_nbrlikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION de ces premiers éléments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- ensuite, nous avons décidé de **créer différents indices** pour aborder autrement les données. \n",
    "1. un taux d'engagement égal à la somme de likes, de retweets, de réponses le tout sur le nombre de vues, exprimé en pourcentages. Nous mettons en place un taux d'engagement par semaine. \n",
    "2. un taux de croissance des interactions : nous nous sommes ici restreints à la variation de likes d'une semaine à l'autre\n",
    "**PONDERER PAR LE NOMBRE DE TWEETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code 3_rap_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois ces indices créés, nous les représentons sur un même graphique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4_graph_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
