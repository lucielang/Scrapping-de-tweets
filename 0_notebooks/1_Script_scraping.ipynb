{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 1 : Scraping des données \n",
    "\n",
    "Le 9 février 2023 l'API de Twitter est devenue payante, de sorte que pour obtenir un nombre illimité de tweets gratuitement, nous avons dû utiliser des méthodes de scraping. \n",
    "\n",
    "Les modules comme snscrape ou twint ne fonctionnaient pas, possiblement en raison du nombre croissant de limitations en ce qui concerne le scraping imposées par Twitter. \n",
    "Afin d'obtenir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "email = input(\"Adresse e-mail : \")\n",
    "username = input(\"Nom d'utilisateur : \")\n",
    "password = input(\"Mot de passe : \")\n",
    "search_query = input(\"Requête : \")\n",
    "start_date = input(\"Date de début : \")\n",
    "end_date = input(\"Date de fin : \")\n",
    "\n",
    "query = f\"({search_query}) lang:en until:{end_date} since:{start_date}\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://x.com/i/flow/login')\n",
    "time.sleep(10)\n",
    "\n",
    "# Connexion\n",
    "username_input = driver.find_element('name', 'text')\n",
    "username_input.send_keys(email)\n",
    "username_input.send_keys(Keys.RETURN)\n",
    "time.sleep(5)\n",
    "\n",
    "webdriver.ActionChains(driver).send_keys(username).perform()\n",
    "webdriver.ActionChains(driver).send_keys(Keys.RETURN).perform()\n",
    "time.sleep(5)\n",
    "\n",
    "password_input = driver.find_element('name', 'password')\n",
    "password_input.send_keys(password)\n",
    "password_input.send_keys(Keys.RETURN)\n",
    "time.sleep(5)\n",
    "\n",
    "# Naviguer vers la recherche\n",
    "explore_button = driver.find_element(By.XPATH, \"//a[@href='/explore']\")\n",
    "explore_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "search_bar = driver.find_element(By.XPATH, \"//input[@aria-label='Search query']\")\n",
    "search_bar.send_keys(query)\n",
    "search_bar.send_keys(Keys.RETURN)\n",
    "time.sleep(7)\n",
    "\n",
    "link = driver.find_element(By.XPATH, \"(//div[@class='css-175oi2r r-18u37iz r-16y2uox r-1wbh5a2 r-tzz3ar r-1pi2tsx r-buy8e9 r-mfh4gg r-2eszeu r-10m9thr r-lltvgl']//a)[2]\")\n",
    "link.click()\n",
    "time.sleep(6)\n",
    "\n",
    "# Listes pour stocker les données des tweets\n",
    "usernames = []\n",
    "dates = []\n",
    "contents = []\n",
    "comments = []\n",
    "repost = []\n",
    "likes = []\n",
    "views = []\n",
    "\n",
    "# Ensemble pour vérifier l'unicité\n",
    "tweets_seen = set()\n",
    "\n",
    "\n",
    "# Fonction pour collecter des tweets\n",
    "def collect_tweets():\n",
    "    new_tweets_found = False \n",
    "    tweet_elements = driver.find_elements(By.XPATH, \"(//div[contains(@class, 'css-175oi2r r-1igl3o0 r-qklmqi r-1adg3ll r-1ny4l3l')])\")\n",
    "    for element in tweet_elements:\n",
    "        try:\n",
    "            username_recup = element.find_element(By.XPATH, \".//a[contains(@class, 'css-175oi2r r-1wbh5a2 r-dnmrzs r-1ny4l3l r-1loqt21')]\").text\n",
    "            date_recup = element.find_element(By.XPATH, \".//div[contains(@class, 'css-175oi2r r-18u37iz r-1q142lx')]\").text\n",
    "            content_recup = element.find_element(By.XPATH, \".//div[contains(@class, 'css-146c3p1 r-8akbws r-krxsd3 r-dnmrzs r-1udh08x r-bcqeeo r-1ttztb7 r-qvutc0 r-37j5jr r-a023e6 r-rjixqe r-16dba41 r-bnwqim')]\").text\n",
    "            stats_recup = element.find_elements(By.XPATH, \".//div[contains(@class, 'css-175oi2r r-xoduu5 r-1udh08x')]\")\n",
    "            comments_recup = stats_recup[0].text\n",
    "            repost_recup = stats_recup[1].text\n",
    "            likes_recup = stats_recup[2].text\n",
    "            views_recup = stats_recup[3].text\n",
    "            tweet_tuple = (username_recup, date_recup, content_recup)\n",
    "            \n",
    "            # Vérifier si le tweet a déjà été vu\n",
    "            if tweet_tuple not in tweets_seen:\n",
    "                tweets_seen.add(tweet_tuple) \n",
    "                usernames.append(username_recup)\n",
    "                dates.append(date_recup)\n",
    "                contents.append(content_recup)\n",
    "                comments.append(comments_recup)\n",
    "                repost.append(repost_recup)\n",
    "                likes.append(likes_recup)\n",
    "                views.append(views_recup)\n",
    "                new_tweets_found = True  # Détecter un nouveau tweet\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return new_tweets_found  # Retourne True si de nouveaux tweets ont été ajoutés\n",
    "\n",
    "\n",
    "# Boucle pour défiler et collecter jusqu'à obtenir 10 000 tweets\n",
    "max_no_new_tweets = 5  # Nombre maximal de tentatives sans nouveaux tweets avant de s'arrêter\n",
    "no_new_tweets_count = 0  # Compteur pour les tentatives sans nouveaux tweets\n",
    "\n",
    "while len(usernames) < 10000 and no_new_tweets_count < max_no_new_tweets:\n",
    "    if collect_tweets():  # Si de nouveaux tweets sont collectés\n",
    "        no_new_tweets_count = 0  # Réinitialiser le compteur si des tweets ont été collectés\n",
    "    else:\n",
    "        no_new_tweets_count += 1  # Si aucun tweet n'est collecté, incrémenter le compteur\n",
    "\n",
    "    # Scrolling pour charger davantage de tweets si aucun nouveau tweet n'est trouvé\n",
    "    for _ in range(5):  # Défiler 5 fois\n",
    "        driver.execute_script(\"window.scrollBy(0, window.innerHeight);\")  # Défiler de la hauteur de la fenêtre\n",
    "        time.sleep(1)  # Attendre le chargement des nouveaux tweets        \n",
    "        # Récupérer des nouveaux tweets après chaque défilement\n",
    "        if collect_tweets():  # Si de nouveaux tweets sont trouvés après le défilement\n",
    "            no_new_tweets_count = 0  # Réinitialiser le compteur\n",
    "            break  # Sort de la boucle si de nouveaux tweets sont trouvés\n",
    "\n",
    "    if no_new_tweets_count >= max_no_new_tweets:  # Si le nombre de tentatives sans nouveaux tweets est trop élevé\n",
    "        print(\"Aucun nouveau tweet trouvé après plusieurs tentatives, arrêt.\")\n",
    "        break\n",
    "\n",
    "print(f\"Total des tweets récupérés : {len(usernames)}\")\n",
    "driver.quit()\n",
    "\n",
    "# Créer un DataFrame et enregistrer les données dans un fichier Excel\n",
    "data = {\n",
    "    'Username': usernames,\n",
    "    'Date': dates,\n",
    "    'Content': contents,\n",
    "    'Comments': comments,\n",
    "    'Repost': repost,\n",
    "    'Likes': likes,\n",
    "    'Views': views\n",
    "}\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"tweets_scrap\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"tweets.xlsx\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel(\"tweets.xlsx\", index=False)\n",
    "print(\"Fichier tweets.xlsx créé avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Username': usernames,\n",
    "    'Date': dates,\n",
    "    'Content': contents,\n",
    "    'Comments': comments,\n",
    "    'Repost': repost,\n",
    "    'Likes': likes,\n",
    "    'Views': views\n",
    "}\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"tweets_scrap\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"tweets.xlsx\")\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
